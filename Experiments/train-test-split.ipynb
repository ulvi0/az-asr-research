{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed mon: 2147 train samples, 503 test samples.\n",
      "Processed dat: 3424 train samples, 655 test samples.\n",
      "Processed tim: 142 train samples, 27 test samples.\n",
      "Processed id: 1952 train samples, 391 test samples.\n",
      "Processed bcd: 644 train samples, 111 test samples.\n",
      "Processed car: 571 train samples, 122 test samples.\n",
      "Processed phn: 664 train samples, 125 test samples.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# --------------------------\n",
    "# 1. Configuration\n",
    "# --------------------------\n",
    "# Base folder where the combined datasets are stored.\n",
    "DATASET_FOLDER = os.path.join(\"..\", \"Data\", \"dataset\")\n",
    "\n",
    "# Create output directories for train and test splits\n",
    "TRAIN_FOLDER = os.path.join(DATASET_FOLDER, \"train\")\n",
    "TEST_FOLDER  = os.path.join(DATASET_FOLDER, \"test\")\n",
    "os.makedirs(TRAIN_FOLDER, exist_ok=True)\n",
    "os.makedirs(TEST_FOLDER, exist_ok=True)\n",
    "\n",
    "# Define the test split fraction (e.g., 20% of speakers for testing)\n",
    "TEST_FRACTION = 0.2\n",
    "\n",
    "# --------------------------\n",
    "# 2. Processing Each Dataset\n",
    "# --------------------------\n",
    "# Find all dataset CSV files in the dataset folder (exclude combined_dataset.csv if present)\n",
    "dataset_files = glob.glob(os.path.join(DATASET_FOLDER, \"*_dataset.csv\"))\n",
    "dataset_files = [f for f in dataset_files if \"combined_dataset.csv\" not in f]\n",
    "\n",
    "for file_path in dataset_files:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Get the unique speakers\n",
    "    speakers = df['speaker'].unique()\n",
    "    \n",
    "    # Determine how many speakers to use for testing (at least one)\n",
    "    n_test = max(1, int(len(speakers) * TEST_FRACTION))\n",
    "    \n",
    "    # Randomly choose speakers for the test set\n",
    "    test_speakers = np.random.choice(speakers, size=n_test, replace=False)\n",
    "    \n",
    "    # Split the dataset: all rows with a speaker in test_speakers go to test set.\n",
    "    train_df = df[~df['speaker'].isin(test_speakers)]\n",
    "    test_df  = df[df['speaker'].isin(test_speakers)]\n",
    "    \n",
    "    # Derive a base name for the output files from the current dataset filename\n",
    "    base_name = os.path.basename(file_path).replace(\"_dataset.csv\", \"\")\n",
    "    \n",
    "    # Define output paths for train and test splits\n",
    "    train_csv  = os.path.join(TRAIN_FOLDER, f\"{base_name}_train.csv\")\n",
    "    train_json = os.path.join(TRAIN_FOLDER, f\"{base_name}_train.json\")\n",
    "    test_csv   = os.path.join(TEST_FOLDER, f\"{base_name}_test.csv\")\n",
    "    test_json  = os.path.join(TEST_FOLDER, f\"{base_name}_test.json\")\n",
    "    \n",
    "    # Save the splits as CSV\n",
    "    train_df.to_csv(train_csv, index=False, encoding=\"utf-8\")\n",
    "    test_df.to_csv(test_csv, index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    # Save the splits as JSON (records-oriented)\n",
    "    train_df.to_json(train_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "    test_df.to_json(test_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Processed {base_name}: {len(train_df)} train samples, {len(test_df)} test samples.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
